# ğŸ§  CÃ“MO SE PENSÃ“ EL MODELO PREDICTIVO

Una explicaciÃ³n conceptual de las decisiones de diseÃ±o.

---

## ğŸ“Œ Problema Original

```
SITUACIÃ“N:
â”œâ”€ Sensores Aire2, Aire4, Aire5 â†’ DEGRADADOS
â”œâ”€ Incertidumbre en mediciones â†’ ALTA
â”œâ”€ Necesidad: Predecir PM futuro â†’ ANTICIPARSE
â””â”€ Objetivo cambiÃ³: Mejor que visual â†’ MODELO PREDICTIVO
```

**Pregunta Central:**
> Â¿Podemos predecir PM2.5 y PM10 1, 3, 5 horas adelante con datos de la estaciÃ³n de referencia (RMCAB)?

---

## ğŸ¤” DecisiÃ³n 1: Â¿Por quÃ© usar LSTM?

### Alternativas Consideradas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MÃ©todo                  â”‚ Ventajas       â”‚ Desventajas  â”‚ Vio Seleccion  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ RegresiÃ³n Lineal        â”‚ Simple         â”‚ Asume lineal â”‚ âŒ             â”‚
â”‚ Polinomial              â”‚ Flexible       â”‚ Overfitting  â”‚ âŒ             â”‚
â”‚ ARIMA                   â”‚ Interpretable  â”‚ Estacionario â”‚ âš ï¸ Fallback   â”‚
â”‚ Prophet (Facebook)      â”‚ AutomÃ¡tico     â”‚ Menos potenteâ”‚ âš ï¸ Fallback   â”‚
â”‚ LSTM âœ“                  â”‚ Temporal       â”‚ Complejo     â”‚ âœ… ELEGIDO    â”‚
â”‚ Transformer             â”‚ Estado arte    â”‚ Datos 1000s  â”‚ âš ï¸ Futuro     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Razones LSTM Elegido

```
1. CAPTURA DEPENDENCIAS TEMPORALES LARGAS

   Problema: PM hoy depende de:
   â”œâ”€ PM ayer        (12h antes)
   â”œâ”€ Viento ayer    (12h antes)
   â”œâ”€ PresiÃ³n 3 dÃ­as (72h antes)
   â””â”€ Ciclo semanal  (168h antes)

   SoluciÃ³n LSTM:
   â”œâ”€ Celda recurrente = MEMORIA
   â”œâ”€ Gates (input/forget/output) = FILTRO INTELIGENTE
   â””â”€ Puede aprender "olvida PM hace 3 meses, recuerda hace 2 dÃ­as"

2. SIN SUPUESTOS RESTRICTIVOS

   RegresiÃ³n: Asume linealidad
   â”œâ”€ PM2.5 = Î± + Î²Ã—Temp + Î³Ã—RH
   â”œâ”€ Â¿Y si relaciÃ³n es cuadrÃ¡tica?
   â””â”€ Â¿Y si depende de interacciones?

   LSTM: Aprende relaciones complejas automÃ¡ticamente
   â””â”€ "Descubre" si es lineal, polinomial, caÃ³tica, etc.

3. MANEJA ENTRADA MULTIVARIABLE NATURALMENTE

   Input:
   â”œâ”€ PM2.5 (histÃ³rico)
   â”œâ”€ Temperatura (histÃ³rico)
   â””â”€ Humedad Relativa (histÃ³rico)

   â†’ Todo entra simultÃ¡neamente
   â†’ Captura interacciones automÃ¡ticamente

4. TOLERA DATOS IMPERFECTOS

   Si falta un punto:
   â”œâ”€ RegresiÃ³n: Se "rompe"
   â””â”€ LSTM: Interpola implÃ­citamente

   Si hay ruido:
   â”œâ”€ RegresiÃ³n: Sensible
   â””â”€ LSTM: Robusto (filtro recurrente)
```

---

## ğŸ¤” DecisiÃ³n 2: Â¿Ventanas de 1, 3, 5 horas?

### Por quÃ© no 24, 48, 72 horas?

```
HORIZONTE vs PREDICTIBILIDAD

La atmÃ³sfera tiene "lÃ­mite de predictibilidad"
(similar a efecto mariposa)

Horizonte (h) â”‚ Incertidumbre â”‚ Fiabilidad â”‚ Uso
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1h            â”‚ Baja          â”‚ âœ… Alta    â”‚ Alertas crÃ­ticas
3h            â”‚ Media         â”‚ âœ… Buena   â”‚ PlanificaciÃ³n
5h            â”‚ Media-Alta    â”‚ âš ï¸ Media   â”‚ Tendencias
12h           â”‚ Alta          â”‚ âŒ Baja    â”‚ Poco Ãºtil
24h+          â”‚ Muy Alta      â”‚ âŒ Muy bajaâ”‚ InÃºtil
```

### RazÃ³n de estos horizontes

```
CICLO DIARIO DE PM2.5

24h = Ciclo completo:
â”œâ”€ 05:00 - MÃ­nimo  (inversiÃ³n tÃ©rmica)
â”œâ”€ 14:00 - MÃ¡ximo  (calentamiento)
â”œâ”€ 19:00 - CaÃ­da   (mezcla vertical)
â””â”€ 24:00 - Ciclo repite

Estrategia:
â”œâ”€ 1h  â†’ Captura cambios rÃ¡pidos (trÃ¡fico, emisiones)
â”œâ”€ 3h  â†’ Captura variabilidad media (dispersiÃ³n)
â””â”€ 5h  â†’ Captura tendencia (ciclo parcial)

No hay razÃ³n de ir mÃ¡s allÃ¡
â””â”€ Error crece exponencialmente > 5h
```

---

## ğŸ¤” DecisiÃ³n 3: Â¿24 pasos histÃ³ricos?

### Window Size

```
WINDOW PEQUEÃ‘O (6h)
â”œâ”€ âœ… MÃ¡s muestras para entrenar
â”œâ”€ âŒ Pierde contexto (falta ciclo diario)
â””â”€ Resultado: Overfitting

WINDOW IDEAL (24h) âœ“
â”œâ”€ âœ… Captura ciclo completo
â”œâ”€ âœ… Contexto suficiente
â””â”€ âœ… Muestras balanceadas

WINDOW GRANDE (72h)
â”œâ”€ âŒ Menos muestras para entrenar
â”œâ”€ âŒ InformaciÃ³n vieja less relevante
â””â”€ Resultado: Underfitting
```

**FÃ³rmula empirica:**
```
W_ideal â‰ˆ PerÃ­odo de ciclo principal
```

Para PM2.5: Ciclo = ~24h â†’ Window = 24h âœ“

---

## ğŸ¤” DecisiÃ³n 4: Â¿Modelos Separados vs Uno Compartido?

### Enfoque Elegido: 3 Modelos Independientes

```
OPCIÃ“N 1: Un modelo predice todo (1h, 3h, 5h)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input: 24 histÃ³rico      â”‚
â”‚ Output: [1h, 3h, 5h]     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Desventajas:
â”œâ”€ Conflicto: Optimizar para 1h vs 5h
â”œâ”€ Errores de 1h afectan a 3h y 5h
â””â”€ Modelo trata de ser "todo" â†’ mediocre en todo

OPCIÃ“N 2: Cascada (predice 1h, input a 3h, etc.)
Step1: Predice 1h
Step2: Usa predicciÃ³n de Step1 â†’ predice 3h
Step3: Usa predicciÃ³n de Step2 â†’ predice 5h
Desventajas:
â”œâ”€ Errores se propagan y amplifican
â”œâ”€ 5h = error de 1h + 3h + 5h
â””â”€ MÃ©tricas irreaales

OPCIÃ“N 3: 3 Modelos Independientes âœ“ ELEGIDO
â”œâ”€ Modelo1: Predice t+1h
â”œâ”€ Modelo2: Predice t+3h
â”œâ”€ Modelo3: Predice t+5h
Ventajas:
â”œâ”€ Cada modelo optimizado para su horizonte
â”œâ”€ Errores no se propagan
â”œâ”€ MÃ©tricas reales e independientes
â”œâ”€ FÃ¡cil de escalar (n modelos = n horizontes)
â””â”€ InterpretaciÃ³n clara
```

**DecisiÃ³n justificada:**
```
âœ“ Claridad: SÃ© exactamente quÃ© predice cada modelo
âœ“ Flexibilidad: Puedo entrenar solo 1h si quiero
âœ“ Realismo: Sin error propagaciÃ³n
âœ“ Escalabilidad: Agregar 7h es trivial
```

---

## ğŸ¤” DecisiÃ³n 5: Â¿Normalizar o No?

### MinMaxScaler [0, 1]

```
Â¿POR QUÃ‰ NORMALIZAR?

Problema Sin Normalizar:
â”œâ”€ PM2.5: Rango 10-100 Î¼g/mÂ³
â”œâ”€ Temperatura: Rango 15-25 Â°C
â”œâ”€ RH: Rango 50-90 %
â”‚
â””â”€ Entrada a LSTM: Magnitudes muy diferentes
   â”œâ”€ LSTM asume varianzas similares
   â”œâ”€ Gradientes exploran espacio mal
   â””â”€ Convergencia lenta o divergencia

SoluciÃ³n: Normalizar [0, 1]
â”œâ”€ PM2.5 â†’ [0, 1]
â”œâ”€ Temp â†’ [0, 1]
â”œâ”€ RH â†’ [0, 1]
â”œâ”€ Todas en escala comparable
â””â”€ LSTM entiende mejor

Cuidado: Mantener escaladores
â”œâ”€ Para entrenar/validar: normalize
â”œâ”€ Para hacer predicciones finales: inverse_transform
â””â”€ Si pierdes escaladores â†’ mÃ©tricas sin sentido
```

**Implementado correctamente:**
```python
scaler_pm25 = MinMaxScaler()  # Separado para cada variable
scaler_temp = MinMaxScaler()
scaler_rh = MinMaxScaler()

# Entrenar
y_pred_scaled = model.predict(X)  # [0, 1]

# Revertir normalizaciÃ³n para mÃ©tricas
y_pred_real = scaler_pm25.inverse_transform(y_pred_scaled)
```

---

## ğŸ¤” DecisiÃ³n 6: Â¿ValidaciÃ³n Temporal o Random?

### Problema de Data Leakage

```
INCORRECTO: Random Split (Â¡COMÃšN!)

Timeline:
â”œâ”€ 2025-06-01 ...
â”œâ”€ 2025-06-15 â† TRAIN
â”œâ”€ 2025-06-20 â† TEST
â”œâ”€ 2025-07-01 â† TRAIN (Â¡Futuro!)
â””â”€ 2025-07-30 â† TEST

Problema:
â”œâ”€ Modelo VE datos futuros en entrenamiento
â”œâ”€ "Aprende a engaÃ±ar" (memoriza patrones)
â”œâ”€ MÃ©tricas son ILUSIÃ“N
â””â”€ En producciÃ³n: FALLA miserablemente

CORRECTO: Temporal Split (Â¡Implementado!)

Timeline:
â”œâ”€ 2025-06-01 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”œâ”€ 2025-06-15 TRAIN                 â”‚
â”œâ”€ 2025-06-30 (75%)                 â”‚
â”œâ”€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”œâ”€ 2025-07-01 TEST                  â”‚
â”œâ”€ 2025-07-30 (25%)                 â”œâ†’ Orden respetado
â”œâ”€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ventaja:
â”œâ”€ Modelo SOLO ve pasado en entrenamiento
â”œâ”€ TEST son datos FUTUROS al entrenamiento
â”œâ”€ Simula uso real: predecir maÃ±ana
â””â”€ MÃ©tricas son REALES y confiables
```

**CÃ³digo Implementado:**
```python
split_idx = int(len(X) * 0.75)  # Ãndice, no random shuffle
X_train = X[:split_idx]          # Primeros 75%
X_test = X[split_idx:]           # Ãšltimos 25%
# Â¡SIN shuffle! â† CRÃTICO
```

---

## ğŸ¤” DecisiÃ³n 7: Â¿QuÃ© MÃ©tricas Usar?

### Las 4 Escogidas

```
MÃ‰TRICA 1: RMSE (Root Mean Squared Error)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RMSE = âˆš[Î£(y - Å·)Â² / n]             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ventajas:
â”œâ”€ Penaliza errores grandes
â”œâ”€ Sensible a outliers
â”œâ”€ En misma unidad que variable (Î¼g/mÂ³)
â””â”€ FÃ¡cil de interpretar

Desventajas:
â”œâ”€ Esconde distribuciÃ³n de errores
â””â”€ Outliers pueden dominar

CUÃNDO USAR: Siempre, es el "estÃ¡ndar"
```

```
MÃ‰TRICA 2: MAE (Mean Absolute Error)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MAE = Î£|y - Å·| / n                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ventajas:
â”œâ”€ Robusto a outliers
â”œâ”€ Error promedio real
â”œâ”€ FÃ¡cil de explicar (en Î¼g/mÂ³)
â””â”€ No penaliza excesivamente errores grandes

Desventajas:
â”œâ”€ No diferencia entre -5 y +5
â””â”€ Menos sensible a variabilidad

CUÃNDO USAR: Cuando hay outliers o valores extremos
```

```
MÃ‰TRICA 3: RÂ² (Coeficiente de DeterminaciÃ³n)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RÂ² = 1 - (SS_res / SS_tot)           â”‚
â”‚ Rango: [0, 1] o negativo             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Â¿QuÃ© significa?
â”œâ”€ RÂ² = 0.95 â†’ Modelo explica 95% de variaciÃ³n
â”œâ”€ RÂ² = 0.50 â†’ Modelo explica 50% de variaciÃ³n
â”œâ”€ RÂ² = 0.00 â†’ Modelo = predecir siempre la media
â””â”€ RÂ² < 0    â†’ Modelo peor que media simple

Ventajas:
â”œâ”€ Comparable entre modelos
â”œâ”€ InterpretaciÃ³n directa: % varianza explicada
â”œâ”€ Esencial para validaciÃ³n
â””â”€ Adimensional [0, 1]

CUÃNDO USAR: Para comparar modelos
```

```
MÃ‰TRICA 4: MAPE (Mean Absolute Percentage Error)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MAPE = Î£|y - Å·| / |y| Ã— 100%        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ventajas:
â”œâ”€ Error en % (fÃ¡cil de comunicar)
â”œâ”€ Independiente de escala
â”œâ”€ Ãštil para valores con diferentes magnitudes
â””â”€ "El modelo se equivoca en promedio 12%"

Desventajas:
â”œâ”€ Indefinido si y = 0
â”œâ”€ Penaliza mÃ¡s errores en valores pequeÃ±os
â””â”€ Puede ser engaÃ±oso

CUÃNDO USAR: Para comunicar a no-tÃ©cnicos
```

**CombinaciÃ³n Ã³ptima implementada:**
```python
# Complementarias:
â”œâ”€ RMSE: Magnitud total de error
â”œâ”€ MAE: Error promedio robusto
â”œâ”€ RÂ²: ProporciÃ³n varianza explicada
â””â”€ MAPE: Porcentaje para comunicar

# AnÃ¡lisis completo:
â”œâ”€ Si RMSE >> MAE â†’ hay outliers
â”œâ”€ Si RÂ² < 0.7 â†’ modelo dÃ©bil
â”œâ”€ Si MAPE alto pero RÂ² alto â†’ escala engaÃ±a
â””â”€ Equilibrio entre 4 mÃ©tricas
```

---

## ğŸ¤” DecisiÃ³n 8: Â¿Arquitectura LSTM?

### Por quÃ© 2 capas LSTM?

```
1 CAPA LSTM
â””â”€ Ventajas: RÃ¡pido, simple
   Desventajas: Poca capacidad (puede no aprender patrones)

2 CAPAS LSTM âœ“ ELEGIDO
â”œâ”€ Layer 1: Captura patrones corto plazo (horas)
â”œâ”€ Layer 2: Captura patrones largo plazo (dÃ­as)
â””â”€ CombinaciÃ³n: Flexible

3+ CAPAS LSTM
â”œâ”€ Ventajas: Mayor capacidad
â”œâ”€ Desventajas: Overfitting, lento
â””â”€ Para nuestros datos: Innecesario
```

### TamaÃ±o de capas: 64 â†’ 32 â†’ 16

```
DISEÃ‘O PIRAMIDAL (Funnel)

Input (24 Ã— 3 = 72)
    â†“
LSTM 64 neuronas
    â†“ (feature extraction)
LSTM 32 neuronas
    â†“ (abstracciÃ³n)
Dense 16 neuronas
    â†“ (compresiÃ³n)
Output 1 neurona
    â†“
PredicciÃ³n

JustificaciÃ³n:
â”œâ”€ Cada capa reduce dimensionalidad
â”œâ”€ Permite feature learning jerÃ¡rquico
â”œâ”€ 64â†’32â†’16 es poder computacional decreciente
â”œâ”€ Alternativa: 32â†’32â†’32 (pero menos flexible)
â””â”€ Alternativa: 128â†’64â†’32 (pero overfitting)
```

### Dropout 0.2

```
Â¿POR QUÃ‰ DROPOUT?

Sin Dropout:
â”œâ”€ Modelo memoriza datos
â”œâ”€ Co-adaptaciÃ³n de neuronas
â””â”€ Overfitting garantizado

Con Dropout 0.2:
â”œâ”€ Durante entrenamiento: desactiva 20% neuronas aleatoriamente
â”œâ”€ Fuerza red a ser robusta
â”œâ”€ GeneralizaciÃ³n mejorada
â””â”€ RegularizaciÃ³n efectiva

Dropout 0.2 (20%)
â”œâ”€ Conservador: Mantiene 80% de computaciÃ³n
â”œâ”€ Evita underfitting: No poda demasiado
â”œâ”€ EstÃ¡ndar: Usado en mayorÃ­a de redes
â””â”€ Valores tÃ­picos: 0.2-0.5
```

---

## ğŸ¤” DecisiÃ³n 9: Â¿Early Stopping?

### Monitoreo de ValidaciÃ³n

```
SIN EARLY STOPPING (Entrenamiento crudo)

Loss
  â”‚
  â”‚   â—â—â—â—
  â”‚â—â—â—    â—â—â—   â† Empieza overfitting aquÃ­
  â”‚           â—â—â—â—
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Ã‰pocas
  0         50

Problema:
â”œâ”€ ContinÃºa entrenando mÃ¡s allÃ¡ del Ã³ptimo
â”œâ”€ Validation loss sube
â”œâ”€ Test performance empeora
â””â”€ Desperdicia tiempo

CON EARLY STOPPING (Inteligente)

Loss
  â”‚
  â”‚   â—â—â—â—
  â”‚â—â—â—    â—â—  â† STOP aquÃ­
  â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Ã‰pocas
  0    ~30

Implementado:
â”œâ”€ Monitor: val_loss
â”œâ”€ Patience: 10 (esperamos 10 Ã©pocas sin mejorÃ­a)
â”œâ”€ Restore best: Guarda mejor modelo
â””â”€ Resultado: ~30 Ã©pocas vs 50, mejor generalizaciÃ³n
```

---

## ğŸ“Š SÃ­ntesis: Decisiones Clave

| DecisiÃ³n | OpciÃ³n | RazÃ³n |
|----------|--------|-------|
| 1. Algoritmo | LSTM | Captura temporal, flexible |
| 2. Horizontes | 1, 3, 5h | Ciclo PM, lÃ­mite predictibilidad |
| 3. Window | 24h | Captura ciclo diario completo |
| 4. Modelos | 3 independientes | Sin propagaciÃ³n errores |
| 5. NormalizaciÃ³n | MinMax [0,1] | Escala comparable, convergencia |
| 6. ValidaciÃ³n | Temporal split | Evita data leakage |
| 7. MÃ©tricas | 4 mÃ©tricas | AnÃ¡lisis completo |
| 8. Capas | 2 LSTM + Dense | Balance capacidad-regularizaciÃ³n |
| 9. Early Stop | SÃ­ (patience=10) | GeneralizaciÃ³n automÃ¡tica |

---

## âœ… Resultado

Un modelo **robusto, interpretable y prÃ¡ctico** que:
- âœ… Predice PM 1, 3, 5 horas adelante
- âœ… Captura patrones no-lineales
- âœ… Se regulariza automÃ¡ticamente
- âœ… Evita data leakage
- âœ… Genera 4 mÃ©tricas complementarias
- âœ… Es replicable y mejora

---

**Nota:** Cada decisiÃ³n fue deliberada y justificada. No hay "magia", solo decisiones informadas basadas en principios de ML y caracterÃ­sticas del problema (series de tiempo de contaminaciÃ³n).
