# ğŸ”® OBJETIVO 2: MODELO PREDICTIVO DE SERIES DE TIEMPO

## ğŸ“‹ DescripciÃ³n General

El **Objetivo 2** cambiÃ³ de una visualizaciÃ³n interactiva a un **modelo predictivo de series de tiempo** que predice PM2.5 y PM10 con 1, 3 y 5 horas de anticipaciÃ³n.

### JustificaciÃ³n
Los sensores de bajo costo (Aire2, Aire4, Aire5) tienen considerable desgaste y degradaciÃ³n en el tiempo. Para compensar esto, se implementÃ³ un modelo predictivo basado en:
- **Datos reales de RMCAB** (estaciÃ³n de referencia de BogotÃ¡)
- **Variables ambientales** (temperatura y humedad relativa)
- **Arquitectura LSTM** (redes neuronales recurrentes)

---

## ğŸ—ï¸ Arquitectura del Modelo

### 1. **Modelo Base: LSTM (Long Short-Term Memory)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ENTRADA (24 pasos temporales)                  â”‚
â”‚  â”œâ”€ PM2.5/PM10 histÃ³rico                        â”‚
â”‚  â”œâ”€ Temperatura (simulada)                      â”‚
â”‚  â””â”€ Humedad Relativa (simulada)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LSTM Layer 1 (64 neuronas)                     â”‚
â”‚  â”œâ”€ Captures temporal dependencies              â”‚
â”‚  â””â”€ Return sequences para siguiente capa        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dropout (0.2) - RegularizaciÃ³n                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LSTM Layer 2 (32 neuronas)                     â”‚
â”‚  â””â”€ Procesa patrones de mÃ¡s alto nivel          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dropout (0.2) - RegularizaciÃ³n                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dense Layer (16 neuronas, ReLU)                â”‚
â”‚  â””â”€ AbstracciÃ³n final                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Output Layer (1 neurona)                       â”‚
â”‚  â””â”€ PredicciÃ³n: PM2.5/PM10 (Î¼g/mÂ³)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. **Ventanas Temporales MÃºltiples**

El modelo entrena **3 modelos independientes** para predecir:
- **+1 hora** adelante
- **+3 horas** adelante
- **+5 horas** adelante

```
Tiempo Real:  â”œâ”€ Ventana histÃ³rica (24h) â”€â”¤ â”œâ”€ PredicciÃ³n â”€â”¤
              t-24h                        t  t+1h  t+3h  t+5h
```

---

## ğŸ“Š PreparaciÃ³n de Datos

### 3.1 Fuentes de Datos

| Componente | Fuente | Tipo | Tratamiento |
|-----------|--------|------|-------------|
| **PM2.5 Referencia** | RMCAB (CSV cache) | Real | Sin cambios |
| **PM10 Referencia** | RMCAB (CSV cache) | Real | Sin cambios |
| **Temperatura** | Simulada | SintÃ©tico | PatrÃ³n sinusoidal + ruido |
| **Humedad Relativa** | Simulada | SintÃ©tico | PatrÃ³n inverso a temperatura |

### 3.2 Flujo de Preprocesamiento

```
1. CARGAR DATOS
   â”œâ”€ PostgreSQL: Sensores (Aire2, Aire4, Aire5)
   â”œâ”€ CSV: RMCAB (pm25_ref, pm10_ref)
   â””â”€ Generar: Temperatura y Humedad

2. LIMPIAR DATOS
   â”œâ”€ Eliminar valores NaN
   â”œâ”€ Ordenar por timestamp
   â””â”€ Verificar rango suficiente

3. NORMALIZAR (MinMaxScaler: [0, 1])
   â”œâ”€ Escalador PM2.5 para objetivo 1
   â”œâ”€ Escalador PM10 para objetivo 2
   â”œâ”€ Escalador Temperatura
   â””â”€ Escalador Humedad Relativa

4. CREAR SECUENCIAS (ventana deslizante)
   â”œâ”€ Input: 24 pasos histÃ³ricos [PM, Temp, RH]
   â”œâ”€ Output: PredicciÃ³n en t+1, t+3, t+5
   â””â”€ Forma: (muestras, 24, 3)

5. DIVIDIR DATOS
   â”œâ”€ Entrenamiento: 75% (respeta orden temporal)
   â”œâ”€ Prueba: 25% (datos futuros)
   â””â”€ Sin mezcla para validez temporal
```

### 3.3 Ejemplo de Secuencia

```
Entrada (X):
Time    PM2.5   Temp   RH
t-24h   25.3    18.2   75%
t-23h   24.8    18.5   74%
...
t-1h    27.1    22.3   68%

Salidas (y):
t+1h  â†’ 28.5  (predicciÃ³n 1 hora)
t+3h  â†’ 30.2  (predicciÃ³n 3 horas)
t+5h  â†’ 31.8  (predicciÃ³n 5 horas)
```

---

## ğŸ§  Entrenamiento del Modelo

### 4.1 ConfiguraciÃ³n HiperparÃ¡metros

```python
# Arquitectura
LSTM_Layer1 = 64 neuronas
LSTM_Layer2 = 32 neuronas
Dense_Layer = 16 neuronas
Dropout = 0.2 (20% de neuronas desactivadas)

# OptimizaciÃ³n
Optimizador: Adam
Learning Rate: 0.001
FunciÃ³n PÃ©rdida: MSE (Mean Squared Error)
MÃ©trica: MAE (Mean Absolute Error)

# Entrenamiento
Ã‰pocas MÃ¡ximas: 50
Batch Size: 8
Early Stopping: 10 Ã©pocas sin mejorÃ­a
ValidaciÃ³n: 25% del conjunto de entrenamiento
```

### 4.2 Proceso de Entrenamiento

```
Para cada Paso (1h, 3h, 5h):
  â”œâ”€ Crear modelo LSTM nuevo
  â”œâ”€ Compilar con Adam optimizer
  â”œâ”€ Entrenar en datos entrenamiento
  â”œâ”€ Validar en datos prueba
  â”œâ”€ Early stopping si no hay mejorÃ­a
  â””â”€ Guardar mejor modelo

Tiempo estimado: 5-10 minutos (depende de datos)
```

### 4.3 RegularizaciÃ³n (Prevenir Overfitting)

| TÃ©cnica | ParÃ¡metro | Efecto |
|---------|-----------|--------|
| **Dropout** | 0.2 | Desactiva 20% neuronas aleatoriamente |
| **Early Stopping** | patience=10 | Detiene si no mejora validaciÃ³n |
| **Split Temporal** | 75/25 | Evita data leakage |

---

## ğŸ“ˆ EvaluaciÃ³n del Modelo

### 5.1 MÃ©tricas de Efectividad

#### **RMSE (Root Mean Squared Error)**
```
RMSE = âˆš[Î£(y_true - y_pred)Â² / n]

â†’ Mide error promedio en escala original (Î¼g/mÂ³)
â†’ Penaliza mÃ¡s errores grandes
â†’ Objetivo: Minimizar (valores bajos son mejores)

InterpretaciÃ³n:
  RMSE < 5   = Excelente predicciÃ³n
  RMSE 5-10  = Buena predicciÃ³n
  RMSE > 15  = PredicciÃ³n dÃ©bil
```

#### **MAE (Mean Absolute Error)**
```
MAE = Î£|y_true - y_pred| / n

â†’ Error promedio absoluto (Î¼g/mÂ³)
â†’ MÃ¡s robusto a outliers que RMSE
â†’ Objetivo: Minimizar

InterpretaciÃ³n:
  MAE = 3 Î¼g/mÂ³ significa:
  En promedio, el modelo se equivoca ~3 Î¼g/mÂ³
```

#### **RÂ² (Coeficiente de DeterminaciÃ³n)**
```
RÂ² = 1 - (SS_res / SS_tot)

â†’ ProporciÃ³n de varianza explicada por modelo [0, 1]
â†’ ComparaciÃ³n con baseline (media simple)
â†’ Objetivo: Maximizar (cercano a 1)

InterpretaciÃ³n:
  RÂ² = 0.95  = Explica 95% de variaciÃ³n (excelente)
  RÂ² = 0.80  = Explica 80% de variaciÃ³n (bueno)
  RÂ² = 0.50  = Explica 50% de variaciÃ³n (mediocre)
  RÂ² < 0     = Peor que predecir siempre la media
```

#### **MAPE (Mean Absolute Percentage Error)**
```
MAPE = Î£|y_true - y_pred| / |y_true| Ã— 100%

â†’ Error porcentual promedio
â†’ Ãštil para valores con diferentes escalas
â†’ Objetivo: Minimizar

InterpretaciÃ³n:
  MAPE = 10% = En promedio, error del 10%
  MAPE = 25% = En promedio, error del 25%
```

### 5.2 Tabla de Resultados Esperados

```
MÃ©trica    1h Adelante    3h Adelante    5h Adelante
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
RMSE       3-6 Î¼g/mÂ³      6-10 Î¼g/mÂ³     10-15 Î¼g/mÂ³
MAE        2-4 Î¼g/mÂ³      4-7 Î¼g/mÂ³      7-12 Î¼g/mÂ³
RÂ²         0.85-0.95      0.75-0.88      0.60-0.80
MAPE       8-15%          12-22%         18-30%
```

**Nota**: Los valores empeoran conforme aumenta el horizonte de predicciÃ³n (mÃ¡xima entropÃ­a).

---

## ğŸ”§ ImplementaciÃ³n TÃ©cnica

### 6.1 Estructura de Archivos

```
fase 4/
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ data_processor.py          # Carga datos RMCAB
â”‚   â”œâ”€â”€ calibration.py             # CalibraciÃ³n sensores
â”‚   â”œâ”€â”€ visualization.py           # GrÃ¡ficos
â”‚   â””â”€â”€ predictive_model.py        # â† NUEVO: Modelo LSTM
â”œâ”€â”€ app.py                         # Flask con endpoints
â”œâ”€â”€ train_predictor.py             # â† NUEVO: Script standalone
â”œâ”€â”€ requirements.txt               # Dependencias actualizadas
â””â”€â”€ results/
    â”œâ”€â”€ predictive_metrics.csv     # Tabla de mÃ©tricas
    â”œâ”€â”€ predictions_PM25.png       # GrÃ¡ficos PM2.5
    â”œâ”€â”€ predictions_PM10.png       # GrÃ¡ficos PM10
    â””â”€â”€ steps_comparison.png       # ComparaciÃ³n pasos
```

### 6.2 Clases Principales

#### **TimeSeriesPreprocessor**
```python
class TimeSeriesPreprocessor:
    """Prepara datos para LSTM"""

    def __init__(lookback_window=24, forecast_steps=[1,3,5])
    def prepare_data(df, target_column, include_features)
        â†’ Retorna: X_train, X_test, y_train, y_test
```

#### **LSTMPredictor**
```python
class LSTMPredictor:
    """Entrena y predice con LSTM"""

    def build_model(input_shape)
        â†’ Crea arquitectura LSTM
    def train(X_train, y_train, X_test, y_test)
        â†’ Entrena modelo
    def predict(X_test, y_test_true, scaler)
        â†’ Realiza predicciones + mÃ©tricas
```

#### **PredictiveModelPipeline**
```python
class PredictiveModelPipeline:
    """Orquesta todo el flujo"""

    def train_and_evaluate(merged_df, output_dir)
        â†’ Ejecuta pipeline completo
        â†’ Genera reportes y grÃ¡ficos
```

---

## ğŸš€ CÃ³mo Usar

### 7.1 InstalaciÃ³n de Dependencias

```bash
# En la carpeta fase 4/
pip install -r requirements.txt

# Principales librerÃ­as agregadas:
# - tensorflow>=2.10.0  (LSTM)
# - matplotlib>=3.5.0   (grÃ¡ficos)
# - seaborn>=0.12.0     (visualizaciÃ³n)
# - statsmodels>=0.13.0 (ARIMA fallback)
```

### 7.2 EjecuciÃ³n OpciÃ³n 1: Script Standalone

```bash
# En carpeta fase 4/
python train_predictor.py

# Salida:
# âœ“ Carga datos de PostgreSQL
# âœ“ Carga RMCAB desde CSV
# âœ“ Entrena modelo LSTM
# âœ“ Genera grÃ¡ficos y mÃ©tricas
```

### 7.3 EjecuciÃ³n OpciÃ³n 2: API REST

```bash
# Iniciar servidor
python app.py

# En otra terminal o cliente HTTP:

# 1. Entrenar modelo
POST http://localhost:5000/api/objetivo2/train-predictor

# Respuesta:
{
  "status": "success",
  "results": {
    "pm25": {
      "1": {"rmse": 4.2, "mae": 3.1, "r2": 0.92, "mape": 12.3},
      "3": {"rmse": 7.1, "mae": 5.2, "r2": 0.85, "mape": 18.5},
      "5": {"rmse": 10.3, "mae": 7.8, "r2": 0.72, "mape": 26.1}
    },
    "pm10": {...}
  }
}

# 2. Obtener mÃ©tricas
GET http://localhost:5000/api/objetivo2/metrics
```

### 7.4 Salida Generada

```
results/
â”œâ”€â”€ predictive_metrics.csv
â”‚   Contaminante, Paso, RMSE, MAE, RÂ², MAPE
â”‚   PM2.5,1,4.2,3.1,0.92,12.3
â”‚   PM2.5,3,7.1,5.2,0.85,18.5
â”‚   PM2.5,5,10.3,7.8,0.72,26.1
â”‚   PM10,1,5.1,4.0,0.88,15.2
â”‚   ...
â”‚
â”œâ”€â”€ predictions_PM25.png
â”‚   - 3 grÃ¡ficos scatter: Valor Real vs Predicho
â”‚   - Para cada paso (1h, 3h, 5h)
â”‚   - Con RÂ² y RMSE en tÃ­tulos
â”‚
â”œâ”€â”€ predictions_PM10.png
â”‚   - Idem PM2.5
â”‚
â””â”€â”€ steps_comparison.png
    - 4 grÃ¡ficos de lÃ­nea
    - RMSE, MAE, RÂ², MAPE vs Pasos
    - ComparaciÃ³n PM2.5 vs PM10
```

---

## ğŸ“š MetodologÃ­a: Paso a Paso

### 8.1 MetodologÃ­a de Entrenamiento

```
FASE 1: PREPARACIÃ“N
â”œâ”€ 1.1 Cargar datos reales (PostgreSQL + CSV)
â”œâ”€ 1.2 Limpiar valores NaN
â”œâ”€ 1.3 Simular temperatura/humedad
â””â”€ 1.4 Verificar integridad datos

FASE 2: NORMALIZACIÃ“N
â”œâ”€ 2.1 Crear escaladores MinMaxScaler
â”œâ”€ 2.2 Escalar todas las variables [0,1]
â”œâ”€ 2.3 Guardar escaladores para inverse_transform
â””â”€ 2.4 Verificar rango normalizado

FASE 3: SECUENCIACIÃ“N
â”œâ”€ 3.1 Crear ventanas deslizantes (24 pasos)
â”œâ”€ 3.2 Generar outputs para t+1, t+3, t+5
â”œâ”€ 3.3 Verificar forma (muestras, timesteps, features)
â””â”€ 3.4 Split 75/25 respetando orden temporal

FASE 4: MODELADO
â”œâ”€ 4.1 Construir arquitectura LSTM
â”œâ”€ 4.2 Compilar con optimizer Adam
â”œâ”€ 4.3 Para cada paso (1h, 3h, 5h):
â”‚      â”œâ”€ Entrenar modelo
â”‚      â”œâ”€ Monitorear validaciÃ³n
â”‚      â”œâ”€ Aplicar early stopping
â”‚      â””â”€ Guardar mejor modelo
â””â”€ 4.4 Verificar convergencia

FASE 5: EVALUACIÃ“N
â”œâ”€ 5.1 PredicciÃ³n en conjunto prueba
â”œâ”€ 5.2 Desnormalizar predicciones
â”œâ”€ 5.3 Calcular 4 mÃ©tricas (RMSE, MAE, RÂ², MAPE)
â”œâ”€ 5.4 Analizar patrones de error
â””â”€ 5.5 Generar reportes

FASE 6: VISUALIZACIÃ“N
â”œâ”€ 6.1 GrÃ¡ficos scatter (Real vs Predicho)
â”œâ”€ 6.2 GrÃ¡ficos de lÃ­nea (ComparaciÃ³n pasos)
â”œâ”€ 6.3 Exportar CSV de mÃ©tricas
â””â”€ 6.4 Guardar con alta resoluciÃ³n (300 DPI)
```

### 8.2 ValidaciÃ³n Temporal (Data Leakage Prevention)

```
PROBLEMA COMÃšN: Data Leakage
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Si mezclamos datos:              â”‚
â”‚ Train: Mix de primeras y Ãºltimas â”‚
â”‚ Test: Also mix                   â”‚
â”‚ â†’ Modelo aprende "trampas"       â”‚
â”‚ â†’ MÃ©tricas artificialmente altas  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

SOLUCIÃ“N IMPLEMENTADA: Respeto Temporal
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test (25%)                       â”‚
â”‚ â”œâ”€ Datos mÃ¡s recientes          â”‚
â”‚ â””â”€ Predice futuro del modelo    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Train (75%)                      â”‚
â”‚ â”œâ”€ Datos mÃ¡s antiguos           â”‚
â”‚ â””â”€ Modelo aprende pasado        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â†’ Split temporal es CRUCIAL para series
â†’ Evita que modelo vea "el futuro"
â†’ MÃ©tricas representan valor real
```

---

## ğŸ“Š AnÃ¡lisis de Resultados

### 9.1 Â¿QuÃ© Significan los Resultados?

#### Escenario 1: Modelo Excelente âœ…
```
RMSE = 3-5 Î¼g/mÂ³
RÂ²   = 0.90-0.95
MAPE = 10-15%

â†’ Modelo es muy preciso
â†’ Puede reemplazar sensores degradados
â†’ Error pequeÃ±o vs magnitud de contaminaciÃ³n
```

#### Escenario 2: Modelo Aceptable âš ï¸
```
RMSE = 8-12 Î¼g/mÂ³
RÂ²   = 0.75-0.85
MAPE = 20-25%

â†’ Modelo es Ãºtil pero con margen
â†’ Recomendable para alertas tempranas
â†’ Requiere validaciÃ³n adicional
```

#### Escenario 3: Modelo DÃ©bil âŒ
```
RMSE = > 15 Î¼g/mÂ³
RÂ²   = < 0.60
MAPE = > 30%

â†’ Modelo no es confiable
â†’ Requiere mÃ¡s datos o mejor arquitectura
â†’ Considerar features adicionales
```

### 9.2 DegraciÃ³n Esperada por Paso

**Es NORMAL que la precisiÃ³n disminuya:**

```
Efecto de Horizonte (Lyapunov Chaos)
â”œâ”€ 1h:   RMSE = 4 Î¼g/mÂ³  (Alta precisiÃ³n)
â”œâ”€ 3h:   RMSE = 8 Î¼g/mÂ³  (50% mÃ¡s error)
â””â”€ 5h:  RMSE = 12 Î¼g/mÂ³ (200% mÃ¡s error)

RazÃ³n:
â”œâ”€ Perturbaciones pequeÃ±as se amplifican
â”œâ”€ Incertidumbre crece exponencialmente
â””â”€ MÃ¡ximo horizonte ~24-48h para PM
```

---

## ğŸ”¬ Mejoras Futuras

### Variaciones Posibles:

1. **Agregar Features Adicionales**
   ```
   - PresiÃ³n atmosfÃ©rica
   - Velocidad del viento
   - DirecciÃ³n del viento
   - RadiaciÃ³n solar
   ```

2. **Arquitecturas Alternativas**
   ```
   - GRU (mÃ¡s rÃ¡pido que LSTM)
   - Attention mechanisms
   - Transformer (estado del arte)
   - ARIMA (mÃ¡s interpretable)
   - Prophet (Facebook)
   ```

3. **Mejoras de ValidaciÃ³n**
   ```
   - Cross-validation temporal
   - Bootstrap del error
   - Intervalos de confianza
   - AnÃ¡lisis de residuos
   ```

4. **Deployment**
   ```
   - Reentrenamiento diario
   - Monitoreo en tiempo real
   - Alertas automÃ¡ticas
   - API para mÃ³viles
   ```

---

## ğŸ¯ ConclusiÃ³n

El modelo predictivo LSTM proporciona:

âœ… **Predicciones 1, 3, 5 horas adelante**
âœ… **MÃ©tricas cuantificables (RMSE, MAE, RÂ², MAPE)**
âœ… **CompensaciÃ³n para sensores degradados**
âœ… **Alertas tempranas de contaminaciÃ³n**
âœ… **Base para aplicaciones en tiempo real**

**Archivos clave:**
- `modules/predictive_model.py` - ImplementaciÃ³n
- `train_predictor.py` - EjecuciÃ³n standalone
- `app.py` - IntegraciÃ³n API REST
- `results/` - GrÃ¡ficos y mÃ©tricas

---

## ğŸ“ Soporte

Para errores o preguntas:
1. Verificar conexiÃ³n a PostgreSQL
2. Verificar archivo `data_rmcab/rmcab_data.csv`
3. Revisar logs en consola
4. Consultar `DATOS_REALES_FLUJO.md` para fuentes de datos

---

*Documento generado: 2025-11-20*
*VersiÃ³n: 1.0*
