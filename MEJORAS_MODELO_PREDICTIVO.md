# ğŸ”§ Correcciones y Mejoras al Modelo Predictivo

## ğŸ“‹ Resumen de Cambios

Se han implementado mÃºltiples mejoras al mÃ³dulo `calibration.py` para resolver problemas comunes en modelos predictivos y mejorar la robustez del sistema de calibraciÃ³n.

---

## âœ¨ Mejoras Implementadas

### 1. **ValidaciÃ³n Cruzada (Cross-Validation)**

**Problema anterior:** Solo se usaba train_test_split simple, lo que podÃ­a llevar a evaluaciones poco confiables.

**SoluciÃ³n:** 
- ImplementaciÃ³n de KFold Cross-Validation (5 folds)
- CÃ¡lculo de RÂ² promedio y desviaciÃ³n estÃ¡ndar
- Mejor estimaciÃ³n del rendimiento real del modelo

```python
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
cv_scores = cross_val_score(model, X_train, y_train, cv=kfold, scoring='r2')
```

**Beneficios:**
- âœ… EvaluaciÃ³n mÃ¡s robusta del modelo
- âœ… DetecciÃ³n de variabilidad en el rendimiento
- âœ… Menor sesgo en la estimaciÃ³n de mÃ©tricas

---

### 2. **DetecciÃ³n AutomÃ¡tica de Overfitting**

**Problema anterior:** No se detectaba cuando un modelo memorizaba los datos de entrenamiento.

**SoluciÃ³n:** Nueva funciÃ³n `detect_overfitting()` que analiza:
- Diferencia entre RÂ² de entrenamiento y test
- Ratio RMSE test/train
- ClasificaciÃ³n de severidad (alta, moderada, ninguna)

**Umbrales:**
- **Overfitting alto**: Î”RÂ² > 0.2 o RMSE ratio > 1.5
- **Overfitting moderado**: Î”RÂ² > 0.1 o RMSE ratio > 1.2
- **OK**: Î”RÂ² â‰¤ 0.1 y RMSE ratio â‰¤ 1.2

**Ejemplo de salida:**
```json
{
  "status": "overfitting",
  "severity": "moderate",
  "message": "Overfitting moderado detectado (Î”RÂ²=0.15, RMSE ratio=1.3)"
}
```

---

### 3. **Manejo Mejorado de Valores AtÃ­picos (Outliers)**

**Problema anterior:** Outliers podÃ­an distorsionar el entrenamiento de los modelos.

**SoluciÃ³n:** 
- Nueva funciÃ³n `remove_outliers()` con dos mÃ©todos:
  - **IQR (Interquartile Range):** Elimina valores fuera de Q1-1.5Ã—IQR y Q3+1.5Ã—IQR
  - **Z-Score:** Elimina valores con |z| > threshold
- AnÃ¡lisis de outliers antes de entrenar
- Reporte de cuÃ¡ntos registros fueron eliminados

**ConfiguraciÃ³n:**
```python
train_and_evaluate_models(
    lowcost_df, 
    rmcab_df, 
    remove_outliers_flag=True,  # Activar eliminaciÃ³n de outliers
    threshold=2.0                # Umbral IQR
)
```

---

### 4. **RegularizaciÃ³n Mejorada**

**Problema anterior:** Modelos podÃ­an sobreajustarse a los datos de entrenamiento.

**Soluciones implementadas:**

#### a) **Ridge Regression**
Nuevo modelo agregado con regularizaciÃ³n L2:
```python
'Ridge Regression': Ridge(alpha=1.0, random_state=42)
```

#### b) **Random Forest Optimizado**
```python
RandomForestRegressor(
    n_estimators=100,      # Ãrboles suficientes
    max_depth=15,          # Limitar profundidad
    min_samples_split=5,   # MÃ­nimo para dividir
    min_samples_leaf=2,    # MÃ­nimo en hojas
    random_state=42
)
```

#### c) **SVR Mejorado**
```python
'SVR (RBF)': SVR(kernel='rbf', C=10.0, gamma='scale', epsilon=0.1)
```

**Beneficios:**
- âœ… Reduce overfitting
- âœ… Mejora generalizaciÃ³n
- âœ… Modelos mÃ¡s estables

---

### 5. **RÂ² Ajustado**

**Problema anterior:** RÂ² puede ser engaÃ±oso cuando se agregan muchas features.

**SoluciÃ³n:** CÃ¡lculo de RÂ² ajustado:

```python
def calculate_adjusted_r2(r2, n_samples, n_features):
    adjusted = 1 - (1 - r2) * (n_samples - 1) / (n_samples - n_features - 1)
    return max(adjusted, 0.0)
```

**FÃ³rmula:**
```
RÂ²_adj = 1 - (1 - RÂ²) Ã— (n - 1) / (n - p - 1)
```
Donde:
- n = nÃºmero de muestras
- p = nÃºmero de features

**Beneficios:**
- âœ… Penaliza modelos con muchas variables
- âœ… Mejor comparaciÃ³n entre modelos
- âœ… MÃ©trica mÃ¡s justa

---

### 6. **Escalado Robusto (RobustScaler)**

**Problema anterior:** StandardScaler es sensible a outliers extremos.

**SoluciÃ³n:** OpciÃ³n de usar RobustScaler:
- Usa la mediana en lugar de la media
- Usa IQR en lugar de desviaciÃ³n estÃ¡ndar
- MÃ¡s robusto ante valores extremos

```python
train_and_evaluate_models(
    lowcost_df,
    rmcab_df,
    use_robust_scaler=True  # Usar RobustScaler
)
```

**ComparaciÃ³n:**
| MÃ©todo | Centro | Escala | Sensibilidad a Outliers |
|--------|--------|--------|-------------------------|
| StandardScaler | Media | Std Dev | Alta |
| RobustScaler | Mediana | IQR | Baja |

---

### 7. **Manejo Mejorado de MAPE**

**Problema anterior:** DivisiÃ³n por cero cuando valores reales = 0.

**SoluciÃ³n:**
```python
def calculate_mape(y_true, y_pred):
    mask = np.abs(y_true) > 1e-10  # Evita valores muy pequeÃ±os
    if not mask.any():
        return 0.0
    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100
    return min(mape, 999.99)  # Limitar valores extremos
```

**Mejoras:**
- âœ… No falla con valores cero
- âœ… Ignora valores muy pequeÃ±os
- âœ… Limita MAPE a valores razonables

---

## ğŸ“Š Nuevas MÃ©tricas Disponibles

Cada modelo ahora retorna:

```python
{
    'model_name': 'Random Forest',
    'r2': 0.9245,                    # RÂ² test
    'r2_train': 0.9567,              # RÂ² train
    'r2_adjusted': 0.9198,           # âœ¨ NUEVO
    'cv_r2_mean': 0.9156,            # âœ¨ NUEVO (cross-validation)
    'cv_r2_std': 0.0234,             # âœ¨ NUEVO (variabilidad CV)
    'rmse': 3.52,
    'rmse_train': 2.14,
    'mae': 2.67,
    'mape': 8.5,
    'overfitting': {                 # âœ¨ NUEVO
        'status': 'ok',
        'severity': 'none',
        'message': 'No se detectÃ³ overfitting'
    }
}
```

---

## ğŸ” Script de DiagnÃ³stico

Se ha creado `test_model_corrections.py` que verifica:

1. âœ… MAPE con valores cero
2. âœ… Train_test_split con pocos datos
3. âœ… NormalizaciÃ³n correcta
4. âœ… DetecciÃ³n de overfitting
5. âœ… IdentificaciÃ³n de outliers
6. âœ… Multicolinealidad
7. âœ… ValidaciÃ³n cruzada

**Ejecutar diagnÃ³stico:**
```bash
cd "C:\Proyecto Maestria 23 Sep\fase 3"
python test_model_corrections.py
```

---

## ğŸ¯ CÃ³mo Usar las Nuevas Funciones

### CalibraciÃ³n BÃ¡sica (con mejoras automÃ¡ticas)
```python
from modules.calibration import train_and_evaluate_models

result = train_and_evaluate_models(
    lowcost_df, 
    rmcab_df,
    pollutant='pm25'
)
```

### CalibraciÃ³n Avanzada (control total)
```python
result = train_and_evaluate_models(
    lowcost_df, 
    rmcab_df,
    pollutant='pm25',
    test_size=0.25,
    device_name='Aire2',
    feature_columns=['pm25_sensor', 'temperature', 'rh'],
    remove_outliers_flag=True,      # Eliminar outliers
    use_robust_scaler=True          # Usar RobustScaler
)
```

### AnÃ¡lisis de Resultados
```python
if result['error']:
    print(f"Error: {result['error']}")
else:
    print(f"Registros originales: {result['records']}")
    print(f"Registros despuÃ©s de limpieza: {result['records_after_cleaning']}")
    print(f"Outliers eliminados: {result['outliers_removed']}")
    print(f"Mejor modelo: {result['best_model']}")
    
    for model in result['results']:
        print(f"\n{model['model_name']}:")
        print(f"  RÂ²: {model['r2']}")
        print(f"  RÂ² ajustado: {model['r2_adjusted']}")
        print(f"  RMSE: {model['rmse']}")
        print(f"  Overfitting: {model['overfitting']['message']}")
```

---

## ğŸ“ˆ ComparaciÃ³n Antes/DespuÃ©s

### Antes de las Mejoras
```python
# Modelos disponibles: 5
# - Linear Regression
# - Random Forest (sin regularizaciÃ³n)
# - SVR Linear
# - SVR RBF
# - SVR Polynomial

# MÃ©tricas: RÂ², RMSE, MAE, MAPE
# Sin detecciÃ³n de overfitting
# Sin validaciÃ³n cruzada
# Sin manejo de outliers
# StandardScaler para todos
```

### DespuÃ©s de las Mejoras
```python
# Modelos disponibles: 6
# - Linear Regression
# - Ridge Regression (âœ¨ NUEVO)
# - Random Forest (optimizado con regularizaciÃ³n)
# - SVR Linear (optimizado)
# - SVR RBF (optimizado)
# - SVR Polynomial (optimizado)

# MÃ©tricas: RÂ², RÂ² ajustado, RÂ² CV, RMSE, MAE, MAPE
# âœ… DetecciÃ³n automÃ¡tica de overfitting
# âœ… ValidaciÃ³n cruzada (KFold)
# âœ… EliminaciÃ³n de outliers (IQR/Z-score)
# âœ… RobustScaler disponible
# âœ… Manejo robusto de MAPE
```

---

## ğŸš€ Impacto en el Proyecto

### Para la Tesis
- âœ… MetodologÃ­a mÃ¡s rigurosa
- âœ… Resultados mÃ¡s confiables
- âœ… DetecciÃ³n de problemas automÃ¡tica
- âœ… Mayor credibilidad cientÃ­fica

### Para la ImplementaciÃ³n
- âœ… Modelos mÃ¡s robustos
- âœ… Mejor generalizaciÃ³n
- âœ… Menos falsos positivos
- âœ… Mayor estabilidad

### Para la PresentaciÃ³n
- âœ… MÃ©tricas mÃ¡s completas
- âœ… AnÃ¡lisis de overfitting
- âœ… ValidaciÃ³n cruzada
- âœ… Tratamiento de outliers

---

## ğŸ“ PrÃ³ximos Pasos Recomendados

### Implementaciones Futuras
1. **GridSearchCV** para optimizaciÃ³n de hiperparÃ¡metros
2. **Feature Selection** automÃ¡tico
3. **Ensemble Methods** (Stacking, Voting)
4. **AnÃ¡lisis de Residuales** detallado
5. **Intervalos de Confianza** para predicciones

### ValidaciÃ³n
1. Probar con datos reales
2. Comparar con versiÃ³n anterior
3. Analizar mejora en mÃ©tricas
4. Documentar resultados

---

## ğŸ”§ Archivos Modificados

1. **`modules/calibration.py`** - MÃ³dulo principal con todas las mejoras
2. **`test_model_corrections.py`** - Script de diagnÃ³stico (nuevo)
3. **`MEJORAS_MODELO_PREDICTIVO.md`** - Esta documentaciÃ³n (nuevo)

---

## ğŸ“š Referencias CientÃ­ficas

1. **Cross-Validation:** Kohavi, R. (1995). "A study of cross-validation and bootstrap for accuracy estimation and model selection"
2. **Ridge Regression:** Hoerl & Kennard (1970). "Ridge Regression: Biased Estimation for Nonorthogonal Problems"
3. **Outlier Detection:** Tukey, J.W. (1977). "Exploratory Data Analysis"
4. **Adjusted RÂ²:** Wherry, R.J. (1931). "A new formula for predicting the shrinkage of the coefficient of multiple correlation"

---

## âœ… Checklist de VerificaciÃ³n

Antes de usar en producciÃ³n:

- [x] âœ… CÃ³digo revisado y documentado
- [x] âœ… Funciones con manejo de errores
- [x] âœ… Script de diagnÃ³stico creado
- [x] âœ… DocumentaciÃ³n completa
- [ ] â³ Pruebas con datos reales
- [ ] â³ ComparaciÃ³n con versiÃ³n anterior
- [ ] â³ ValidaciÃ³n con expertos
- [ ] â³ IntegraciÃ³n con frontend

---

**Fecha de implementaciÃ³n:** 5 de noviembre de 2025  
**VersiÃ³n:** 2.0  
**Autor:** Sistema de mejora continua  

---

## ğŸ’¡ Notas Importantes

1. Las mejoras son **retrocompatibles** - el cÃ³digo anterior sigue funcionando
2. Los nuevos parÃ¡metros son **opcionales** - valores por defecto apropiados
3. La eliminaciÃ³n de outliers puede **reducir el tamaÃ±o del dataset** - verificar `records_after_cleaning`
4. La validaciÃ³n cruzada solo se ejecuta con **â‰¥100 registros** para evitar problemas

---

**Â¡Tu modelo predictivo ahora es mucho mÃ¡s robusto y confiable! ğŸ‰**
